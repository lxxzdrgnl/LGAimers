{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80ef4238-25b3-4737-bf04-9234d046ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import optuna\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "train = pd.read_csv(\"../data/train.csv\").drop(columns=['ID'])\n",
    "test = pd.read_csv(\"../data/test.csv\").drop(columns=['ID'])\n",
    "\n",
    "X = train.drop('ì„ì‹  ì„±ê³µ ì—¬ë¶€', axis=1)\n",
    "y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']\n",
    "\n",
    "categorical_columns = [\n",
    "    \"ì‹œìˆ  ì‹œê¸° ì½”ë“œ\", \"ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´\", \"ì‹œìˆ  ìœ í˜•\", \"íŠ¹ì • ì‹œìˆ  ìœ í˜•\", \"ë°°ë€ ìê·¹ ì—¬ë¶€\", \"ë°°ë€ ìœ ë„ ìœ í˜•\",\n",
    "    \"ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€\", \"ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€\", \"ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€\", \"ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸\", \"ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸\", \"ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸\", \"ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸\", \"ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸\",\n",
    "    \"ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸\", \"ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜\", \"ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• \",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ\", \"ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦\", \"ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„\",\n",
    "    \"ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸\", \"ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±\", \"ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ\", \"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \",\n",
    "    \"ì´ ì‹œìˆ  íšŸìˆ˜\", \"í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜\", \"IVF ì‹œìˆ  íšŸìˆ˜\", \"DI ì‹œìˆ  íšŸìˆ˜\", \"ì´ ì„ì‹  íšŸìˆ˜\", \"IVF ì„ì‹  íšŸìˆ˜\",\n",
    "    \"DI ì„ì‹  íšŸìˆ˜\", \"ì´ ì¶œì‚° íšŸìˆ˜\", \"IVF ì¶œì‚° íšŸìˆ˜\", \"DI ì¶œì‚° íšŸìˆ˜\", \"ë‚œì ì¶œì²˜\", \"ì •ì ì¶œì²˜\",\n",
    "    \"ë‚œì ê¸°ì¦ì ë‚˜ì´\", \"ì •ì ê¸°ì¦ì ë‚˜ì´\", \"ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\", \"ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€\",\n",
    "    \"ëŒ€ë¦¬ëª¨ ì—¬ë¶€\", \"PGD ì‹œìˆ  ì—¬ë¶€\", \"PGS ì‹œìˆ  ì—¬ë¶€\"\n",
    "]\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬í˜• ì»¬ëŸ¼ì„ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "X[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "test[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "numeric_columns = [\n",
    "    \"ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜\", \"ì´ ìƒì„± ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜\", \"ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"ì´ì‹ëœ ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜\", \"ì €ì¥ëœ ë°°ì•„ ìˆ˜\", \"ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜\", \"í•´ë™ëœ ë°°ì•„ ìˆ˜\",\n",
    "    \"í•´ë™ ë‚œì ìˆ˜\", \"ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜\", \"í˜¼í•©ëœ ë‚œì ìˆ˜\", \"íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\",\n",
    "    \"ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜\", \"ë‚œì ì±„ì·¨ ê²½ê³¼ì¼\", \"ë‚œì í•´ë™ ê²½ê³¼ì¼\", \"ë‚œì í˜¼í•© ê²½ê³¼ì¼\", \"ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼\",\n",
    "    \"ë°°ì•„ í•´ë™ ê²½ê³¼ì¼\"\n",
    "]\n",
    "\n",
    "X[numeric_columns] = X[numeric_columns].fillna(0)\n",
    "test[numeric_columns] = test[numeric_columns].fillna(0)\n",
    "\n",
    "# ğŸ¯ 1:1 ë¹„ìœ¨ë¡œ Test ë°ì´í„° ë¶„í•  (20% ì¤‘ ì ˆë°˜ì´ 1, ì ˆë°˜ì´ 0)\n",
    "test_size = int(len(y) * 0.2 / 2)\n",
    "\n",
    "y_0 = y[y == 0]\n",
    "y_1 = y[y == 1]\n",
    "\n",
    "# 1ê³¼ 0ì—ì„œ ë™ì¼í•œ ê°œìˆ˜ ì¶”ì¶œ (ê°ê° test_sizeë§Œí¼)\n",
    "y_test_0 = y_0.sample(n=test_size, random_state=42)\n",
    "y_test_1 = y_1.sample(n=test_size, random_state=42)\n",
    "\n",
    "# ë‚˜ë¨¸ì§€ ë°ì´í„°ëŠ” trainìœ¼ë¡œ ì‚¬ìš©\n",
    "y_train_0 = y_0.drop(y_test_0.index)\n",
    "y_train_1 = y_1.drop(y_test_1.index)\n",
    "\n",
    "# Xë„ ë™ì¼í•˜ê²Œ ë§ì¶°ì¤Œ\n",
    "X_test = pd.concat([X.loc[y_test_0.index], X.loc[y_test_1.index]])\n",
    "y_test = pd.concat([y_test_0, y_test_1])\n",
    "\n",
    "X_train = pd.concat([X.loc[y_train_0.index], X.loc[y_train_1.index]])\n",
    "y_train = pd.concat([y_train_0, y_train_1])\n",
    "\n",
    "# ğŸ¯ ì–¸ë”ìƒ˜í”Œë§ ì ìš© (0ê³¼ 1ì„ ë™ì¼ ê°œìˆ˜ë¡œ ë§ì¶¤)\n",
    "rus = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e703ffb-e18e-48a7-8b82-1e31579ecc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-18 00:30:29,715] A new study created in memory with name: no-name-53192310-6712-4ec0-b130-4a58f1a52f7a\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:31:16,154] Trial 0 finished with value: 0.6663740979130096 and parameters: {'lr_C': 4.007546644678651, 'dt_max_depth': 13, 'knn_neighbors': 14, 'rf_n_estimators': 218, 'voting': 'soft'}. Best is trial 0 with value: 0.6663740979130096.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:31:46,195] Trial 1 finished with value: 0.6671542812560952 and parameters: {'lr_C': 8.744150624938326, 'dt_max_depth': 14, 'knn_neighbors': 14, 'rf_n_estimators': 97, 'voting': 'hard'}. Best is trial 1 with value: 0.6671542812560952.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:32:18,951] Trial 2 finished with value: 0.6619075482738443 and parameters: {'lr_C': 0.8585177494818456, 'dt_max_depth': 2, 'knn_neighbors': 14, 'rf_n_estimators': 135, 'voting': 'hard'}. Best is trial 1 with value: 0.6671542812560952.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:33:00,850] Trial 3 finished with value: 0.6666471620830895 and parameters: {'lr_C': 4.188245557754772, 'dt_max_depth': 4, 'knn_neighbors': 8, 'rf_n_estimators': 218, 'voting': 'soft'}. Best is trial 1 with value: 0.6671542812560952.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:33:21,728] Trial 4 finished with value: 0.6630583187048956 and parameters: {'lr_C': 0.4892124962728546, 'dt_max_depth': 12, 'knn_neighbors': 5, 'rf_n_estimators': 66, 'voting': 'soft'}. Best is trial 1 with value: 0.6671542812560952.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:34:14,376] Trial 5 finished with value: 0.6657499512385411 and parameters: {'lr_C': 5.721405581949467, 'dt_max_depth': 14, 'knn_neighbors': 13, 'rf_n_estimators': 291, 'voting': 'soft'}. Best is trial 1 with value: 0.6671542812560952.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:34:52,288] Trial 6 finished with value: 0.6628047591183929 and parameters: {'lr_C': 9.394424165596327, 'dt_max_depth': 15, 'knn_neighbors': 4, 'rf_n_estimators': 175, 'voting': 'hard'}. Best is trial 1 with value: 0.6671542812560952.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:35:43,714] Trial 7 finished with value: 0.6677979325141408 and parameters: {'lr_C': 7.053323663273489, 'dt_max_depth': 10, 'knn_neighbors': 13, 'rf_n_estimators': 282, 'voting': 'soft'}. Best is trial 7 with value: 0.6677979325141408.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:36:31,433] Trial 8 finished with value: 0.6667446850009753 and parameters: {'lr_C': 3.5375833815161277, 'dt_max_depth': 16, 'knn_neighbors': 15, 'rf_n_estimators': 238, 'voting': 'hard'}. Best is trial 7 with value: 0.6677979325141408.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:37:11,323] Trial 9 finished with value: 0.6663350887458552 and parameters: {'lr_C': 5.265517847621868, 'dt_max_depth': 3, 'knn_neighbors': 7, 'rf_n_estimators': 186, 'voting': 'hard'}. Best is trial 7 with value: 0.6677979325141408.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:38:04,511] Trial 10 finished with value: 0.6684025746050322 and parameters: {'lr_C': 7.434642563325552, 'dt_max_depth': 8, 'knn_neighbors': 11, 'rf_n_estimators': 296, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:38:57,732] Trial 11 finished with value: 0.668110005851375 and parameters: {'lr_C': 7.490193034088178, 'dt_max_depth': 8, 'knn_neighbors': 11, 'rf_n_estimators': 290, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:39:47,250] Trial 12 finished with value: 0.6678954554320266 and parameters: {'lr_C': 7.128054264616271, 'dt_max_depth': 8, 'knn_neighbors': 11, 'rf_n_estimators': 268, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:40:41,900] Trial 13 finished with value: 0.6549444119368052 and parameters: {'lr_C': 7.394841397744262, 'dt_max_depth': 20, 'knn_neighbors': 10, 'rf_n_estimators': 300, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:41:29,092] Trial 14 finished with value: 0.667680905012678 and parameters: {'lr_C': 8.39375737211465, 'dt_max_depth': 7, 'knn_neighbors': 11, 'rf_n_estimators': 253, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:42:04,597] Trial 15 finished with value: 0.6672322995904038 and parameters: {'lr_C': 6.450208901019623, 'dt_max_depth': 8, 'knn_neighbors': 9, 'rf_n_estimators': 174, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:42:50,141] Trial 16 finished with value: 0.6671737858396724 and parameters: {'lr_C': 9.918732345100986, 'dt_max_depth': 6, 'knn_neighbors': 11, 'rf_n_estimators': 239, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:43:38,551] Trial 17 finished with value: 0.6638580066315584 and parameters: {'lr_C': 2.459320470367008, 'dt_max_depth': 10, 'knn_neighbors': 6, 'rf_n_estimators': 265, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:44:20,248] Trial 18 finished with value: 0.6671737858396724 and parameters: {'lr_C': 8.037693582098463, 'dt_max_depth': 10, 'knn_neighbors': 9, 'rf_n_estimators': 211, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:44:51,931] Trial 19 finished with value: 0.6677004095962551 and parameters: {'lr_C': 6.123357433075873, 'dt_max_depth': 6, 'knn_neighbors': 12, 'rf_n_estimators': 145, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:45:42,606] Trial 20 finished with value: 0.6599960990832846 and parameters: {'lr_C': 7.982417911687189, 'dt_max_depth': 5, 'knn_neighbors': 3, 'rf_n_estimators': 278, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:46:32,233] Trial 21 finished with value: 0.668110005851375 and parameters: {'lr_C': 6.871676376843744, 'dt_max_depth': 8, 'knn_neighbors': 11, 'rf_n_estimators': 263, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:47:18,319] Trial 22 finished with value: 0.6678564462648723 and parameters: {'lr_C': 6.534956794293011, 'dt_max_depth': 8, 'knn_neighbors': 10, 'rf_n_estimators': 245, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:48:12,624] Trial 23 finished with value: 0.6683440608543008 and parameters: {'lr_C': 4.7683499640428995, 'dt_max_depth': 11, 'knn_neighbors': 12, 'rf_n_estimators': 300, 'voting': 'soft'}. Best is trial 10 with value: 0.6684025746050322.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:49:06,391] Trial 24 finished with value: 0.6685196021064951 and parameters: {'lr_C': 4.5693651853372454, 'dt_max_depth': 11, 'knn_neighbors': 12, 'rf_n_estimators': 294, 'voting': 'soft'}. Best is trial 24 with value: 0.6685196021064951.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:49:59,985] Trial 25 finished with value: 0.6616539886873415 and parameters: {'lr_C': 2.757449013422511, 'dt_max_depth': 17, 'knn_neighbors': 12, 'rf_n_estimators': 296, 'voting': 'soft'}. Best is trial 24 with value: 0.6685196021064951.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:50:52,755] Trial 26 finished with value: 0.6679149600156037 and parameters: {'lr_C': 4.920427705018627, 'dt_max_depth': 12, 'knn_neighbors': 13, 'rf_n_estimators': 277, 'voting': 'hard'}. Best is trial 24 with value: 0.6685196021064951.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-18 00:51:36,409] Trial 27 finished with value: 0.6682855471035694 and parameters: {'lr_C': 4.638821869259635, 'dt_max_depth': 11, 'knn_neighbors': 12, 'rf_n_estimators': 227, 'voting': 'soft'}. Best is trial 24 with value: 0.6685196021064951.\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Optuna ìµœì í™” í•¨ìˆ˜\n",
    "def objective(trial):\n",
    "    lr_C = trial.suggest_float(\"lr_C\", 0.01, 10.0)\n",
    "    dt_max_depth = trial.suggest_int(\"dt_max_depth\", 2, 20)\n",
    "    knn_neighbors = trial.suggest_int(\"knn_neighbors\", 3, 15)\n",
    "    rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 50, 300)\n",
    "    \n",
    "    models = [\n",
    "        ('lr', LogisticRegression(C=lr_C, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(max_depth=dt_max_depth, random_state=42)),\n",
    "        ('lda', LinearDiscriminantAnalysis()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=rf_n_estimators, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=knn_neighbors))\n",
    "    ]\n",
    "    \n",
    "    voting_type = trial.suggest_categorical(\"voting\", [\"hard\", \"soft\"])\n",
    "    model = VotingClassifier(estimators=models, voting=voting_type)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Optuna ì‹¤í–‰\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°\n",
    "best_params = study.best_params\n",
    "\n",
    "# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ìƒì„±\n",
    "models = [\n",
    "    ('lr', LogisticRegression(C=best_params['lr_C'], random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=best_params['dt_max_depth'], random_state=42)),\n",
    "    ('lda', LinearDiscriminantAnalysis()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=best_params['rf_n_estimators'], random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=best_params['knn_neighbors']))\n",
    "]\n",
    "\n",
    "# í•˜ë“œ ë³´íŒ… ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "hard_voting_model = VotingClassifier(estimators=models, voting='hard')\n",
    "hard_voting_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_hard = hard_voting_model.predict(X_test)\n",
    "\n",
    "# ì†Œí”„íŠ¸ ë³´íŒ… ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "soft_voting_model = VotingClassifier(estimators=models, voting='soft')\n",
    "soft_voting_model.fit(X_train_resampled, y_train_resampled)\n",
    "y_pred_soft = soft_voting_model.predict(X_test)\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "hard_acc = accuracy_score(y_test, y_pred_hard)\n",
    "soft_acc = accuracy_score(y_test, y_pred_soft)\n",
    "\n",
    "hard_cm = confusion_matrix(y_test, y_pred_hard)\n",
    "soft_cm = confusion_matrix(y_test, y_pred_soft)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"Hard Voting Accuracy:\", hard_acc)\n",
    "print(\"Hard Voting Confusion Matrix:\\n\", hard_cm)\n",
    "print(\"\\nSoft Voting Accuracy:\", soft_acc)\n",
    "print(\"Soft Voting Confusion Matrix:\\n\", soft_cm)\n",
    "\n",
    "# ìµœì  ëª¨ë¸ë¡œ ìµœì¢… ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "y_pred_final = soft_voting_model.predict(test)\n",
    "\n",
    "# ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "sample_submission = pd.read_csv('../submission/sample_submission.csv')\n",
    "sample_submission['prediction'] = y_pred_final\n",
    "sample_submission.to_csv('../submission/baseline_submit2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
