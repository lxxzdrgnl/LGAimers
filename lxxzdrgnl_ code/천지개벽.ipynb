{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80ef4238-25b3-4737-bf04-9234d046ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import optuna\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv(\"../data/train.csv\").drop(columns=['ID'])\n",
    "test = pd.read_csv(\"../data/test.csv\").drop(columns=['ID'])\n",
    "\n",
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "categorical_columns = [\n",
    "    \"시술 시기 코드\", \"시술 당시 나이\", \"시술 유형\", \"특정 시술 유형\", \"배란 자극 여부\", \"배란 유도 유형\",\n",
    "    \"단일 배아 이식 여부\", \"착상 전 유전 검사 사용 여부\", \"착상 전 유전 진단 사용 여부\", \"남성 주 불임 원인\",\n",
    "    \"남성 부 불임 원인\", \"여성 주 불임 원인\", \"여성 부 불임 원인\", \"부부 주 불임 원인\", \"부부 부 불임 원인\",\n",
    "    \"불명확 불임 원인\", \"불임 원인 - 난관 질환\", \"불임 원인 - 남성 요인\", \"불임 원인 - 배란 장애\",\n",
    "    \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\", \"불임 원인 - 정자 농도\",\n",
    "    \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\", \"불임 원인 - 정자 형태\", \"배아 생성 주요 이유\",\n",
    "    \"총 시술 횟수\", \"클리닉 내 총 시술 횟수\", \"IVF 시술 횟수\", \"DI 시술 횟수\", \"총 임신 횟수\", \"IVF 임신 횟수\",\n",
    "    \"DI 임신 횟수\", \"총 출산 횟수\", \"IVF 출산 횟수\", \"DI 출산 횟수\", \"난자 출처\", \"정자 출처\",\n",
    "    \"난자 기증자 나이\", \"정자 기증자 나이\", \"동결 배아 사용 여부\", \"신선 배아 사용 여부\", \"기증 배아 사용 여부\",\n",
    "    \"대리모 여부\", \"PGD 시술 여부\", \"PGS 시술 여부\"\n",
    "]\n",
    "\n",
    "# 카테고리형 컬럼을 문자열로 변환\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "X_train_encoded = X.copy()\n",
    "X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "X_test_encoded = test.copy()\n",
    "X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "numeric_columns = [\n",
    "    \"임신 시도 또는 마지막 임신 경과 연수\", \"총 생성 배아 수\", \"미세주입된 난자 수\", \"미세주입에서 생성된 배아 수\",\n",
    "    \"이식된 배아 수\", \"미세주입 배아 이식 수\", \"저장된 배아 수\", \"미세주입 후 저장된 배아 수\", \"해동된 배아 수\",\n",
    "    \"해동 난자 수\", \"수집된 신선 난자 수\", \"저장된 신선 난자 수\", \"혼합된 난자 수\", \"파트너 정자와 혼합된 난자 수\",\n",
    "    \"기증자 정자와 혼합된 난자 수\", \"난자 채취 경과일\", \"난자 해동 경과일\", \"난자 혼합 경과일\", \"배아 이식 경과일\",\n",
    "    \"배아 해동 경과일\"\n",
    "]\n",
    "\n",
    "X_train_encoded[numeric_columns] = X_train_encoded[numeric_columns].fillna(0)\n",
    "X_test_encoded[numeric_columns] = X_test_encoded[numeric_columns].fillna(0)\n",
    "\n",
    "# 🎯 1:1 비율로 Test 데이터 분할 (20% 중 절반이 1, 절반이 0)\n",
    "test_size = int(len(y) * 0.2 / 2)\n",
    "\n",
    "y_0 = y[y == 0]\n",
    "y_1 = y[y == 1]\n",
    "\n",
    "# 1과 0에서 동일한 개수 추출 (각각 test_size만큼)\n",
    "y_test_0 = y_0.sample(n=test_size, random_state=42)\n",
    "y_test_1 = y_1.sample(n=test_size, random_state=42)\n",
    "\n",
    "# 나머지 데이터는 train으로 사용\n",
    "y_train_0 = y_0.drop(y_test_0.index)\n",
    "y_train_1 = y_1.drop(y_test_1.index)\n",
    "\n",
    "# X도 동일하게 맞춰줌\n",
    "X_test = pd.concat([X.loc[y_test_0.index], X.loc[y_test_1.index]])\n",
    "y_test = pd.concat([y_test_0, y_test_1])\n",
    "\n",
    "X_train = pd.concat([X.loc[y_train_0.index], X.loc[y_train_1.index]])\n",
    "y_train = pd.concat([y_train_0, y_train_1])\n",
    "\n",
    "# 🎯 언더샘플링 적용 (0과 1을 동일 개수로 맞춤)\n",
    "rus = RandomUnderSampler(sampling_strategy=1.0, random_state=42)\n",
    "X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e703ffb-e18e-48a7-8b82-1e31579ecc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-18 01:06:37,136] A new study created in memory with name: no-name-e6395030-bec8-460b-8f8d-605d8e3258ba\n",
      "[W 2025-02-18 01:06:37,332] Trial 0 failed with parameters: {'lr_C': 3.5173800853493775, 'dt_max_depth': 17, 'knn_neighbors': 4, 'rf_n_estimators': 242, 'voting': 'soft'} because of the following error: ValueError(\"could not convert string to float: 'TRJXFG'\").\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\AppData\\Local\\Temp\\ipykernel_17868\\301164215.py\", line 27, in objective\n",
      "    model.fit(X_train_resampled, y_train_resampled)\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 66, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 423, in fit\n",
      "    return super().fit(X, transformed_y, **fit_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py\", line 104, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py\", line 40, in _fit_single_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n",
      "    X, y = self._validate_data(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n",
      "    X = check_array(\n",
      "        ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 751, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n",
      "    arr = np.asarray(values, dtype=dtype)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ValueError: could not convert string to float: 'TRJXFG'\n",
      "[W 2025-02-18 01:06:37,344] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'TRJXFG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Optuna 실행\u001b[39;00m\n\u001b[0;32m     32\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)  \u001b[38;5;66;03m# 더 많은 탐색을 수행\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# 최적 하이퍼파라미터 가져오기\u001b[39;00m\n\u001b[0;32m     36\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     _optimize(\n\u001b[0;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    485\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[0;32m     64\u001b[0m             study,\n\u001b[0;32m     65\u001b[0m             func,\n\u001b[0;32m     66\u001b[0m             n_trials,\n\u001b[0;32m     67\u001b[0m             timeout,\n\u001b[0;32m     68\u001b[0m             catch,\n\u001b[0;32m     69\u001b[0m             callbacks,\n\u001b[0;32m     70\u001b[0m             gc_after_trial,\n\u001b[0;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     74\u001b[0m         )\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     18\u001b[0m models \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     19\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(C\u001b[38;5;241m=\u001b[39mlr_C, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[0;32m     20\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m, DecisionTreeClassifier(max_depth\u001b[38;5;241m=\u001b[39mdt_max_depth, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m, KNeighborsClassifier(n_neighbors\u001b[38;5;241m=\u001b[39mknn_neighbors))\n\u001b[0;32m     24\u001b[0m ]\n\u001b[0;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m VotingClassifier(estimators\u001b[38;5;241m=\u001b[39mmodels, voting\u001b[38;5;241m=\u001b[39mvoting_type)\n\u001b[1;32m---> 27\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_resampled, y_train_resampled)\n\u001b[0;32m     28\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:66\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     69\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[0;32m     72\u001b[0m ]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:423\u001b[0m, in \u001b[0;36mVotingClassifier.fit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m     fit_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 423\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, transformed_y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_voting.py:104\u001b[0m, in \u001b[0;36m_BaseVoting.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m fit_params:\n\u001b[0;32m    100\u001b[0m             routed_params[name]\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fit_params[\n\u001b[0;32m    101\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m             ]\n\u001b[1;32m--> 104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[0;32m    105\u001b[0m     delayed(_fit_single_estimator)(\n\u001b[0;32m    106\u001b[0m         clone(clf),\n\u001b[0;32m    107\u001b[0m         X,\n\u001b[0;32m    108\u001b[0m         y,\n\u001b[0;32m    109\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    110\u001b[0m         message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVoting\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(name, idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(clfs)),\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, clf) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(names, clfs))\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m clf \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m )\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_estimators_ \u001b[38;5;241m=\u001b[39m Bunch()\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# Uses 'drop' as placeholder for dropped estimators\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:40\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[1;34m(estimator, X, y, fit_params, message_clsname, message)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m---> 40\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1223\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1221\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1223\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1224\u001b[0m     X,\n\u001b[0;32m   1225\u001b[0m     y,\n\u001b[0;32m   1226\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m_dtype,\n\u001b[0;32m   1228\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1229\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39msolver \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1230\u001b[0m )\n\u001b[0;32m   1231\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:2153\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\n\u001b[0;32m   2150\u001b[0m     \u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, copy: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2151\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m   2152\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 2153\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(values, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2155\u001b[0m         astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2156\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   2157\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mis_single_block\n\u001b[0;32m   2158\u001b[0m     ):\n\u001b[0;32m   2159\u001b[0m         \u001b[38;5;66;03m# Check if both conversions can be done without a copy\u001b[39;00m\n\u001b[0;32m   2160\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m astype_is_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(\n\u001b[0;32m   2161\u001b[0m             values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2162\u001b[0m         ):\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'TRJXFG'"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Optuna 최적화 함수\n",
    "def objective(trial):\n",
    "    lr_C = trial.suggest_float(\"lr_C\", 0.01, 10.0)\n",
    "    dt_max_depth = trial.suggest_int(\"dt_max_depth\", 2, 20)\n",
    "    knn_neighbors = trial.suggest_int(\"knn_neighbors\", 3, 15)\n",
    "    rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 50, 300)\n",
    "    voting_type = trial.suggest_categorical(\"voting\", [\"hard\", \"soft\"])\n",
    "\n",
    "    models = [\n",
    "        ('lr', LogisticRegression(C=lr_C, random_state=42)),\n",
    "        ('dt', DecisionTreeClassifier(max_depth=dt_max_depth, random_state=42)),\n",
    "        ('lda', LinearDiscriminantAnalysis()),\n",
    "        ('rf', RandomForestClassifier(n_estimators=rf_n_estimators, random_state=42)),\n",
    "        ('knn', KNeighborsClassifier(n_neighbors=knn_neighbors))\n",
    "    ]\n",
    "\n",
    "    model = VotingClassifier(estimators=models, voting=voting_type)\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Optuna 실행\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)  # 더 많은 탐색을 수행\n",
    "\n",
    "# 최적 하이퍼파라미터 가져오기\n",
    "best_params = study.best_params\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 생성\n",
    "models = [\n",
    "    ('lr', LogisticRegression(C=best_params['lr_C'], random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier(max_depth=best_params['dt_max_depth'], random_state=42)),\n",
    "    ('lda', LinearDiscriminantAnalysis()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=best_params['rf_n_estimators'], random_state=42)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=best_params['knn_neighbors']))\n",
    "]\n",
    "\n",
    "final_voting_type = best_params[\"voting\"]\n",
    "final_model = VotingClassifier(estimators=models, voting=final_voting_type)\n",
    "final_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 최종 예측 수행\n",
    "y_pred_final = final_model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b24a58-f12c-4d32-bba0-de88c6486f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Fail\", \"Success\"], yticklabels=[\"Fail\", \"Success\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# 평가\n",
    "y_pred_hard = VotingClassifier(estimators=models, voting=\"hard\").fit(X_train_resampled, y_train_resampled).predict(X_test)\n",
    "y_pred_soft = VotingClassifier(estimators=models, voting=\"soft\").fit(X_train_resampled, y_train_resampled).predict(X_test)\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred_hard, \"Hard Voting Confusion Matrix\")\n",
    "plot_confusion_matrix(y_test, y_pred_soft, \"Soft Voting Confusion Matrix\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9e90ea-597d-43e6-9b24-97687adc888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import  OrdinalEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "train = pd.read_csv(\"../data/train.csv\").drop(columns=['ID'])\n",
    "test = pd.read_csv(\"../data/test.csv\").drop(columns=['ID'])\n",
    "\n",
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "categorical_columns = [\n",
    "    \"시술 시기 코드\",\n",
    "    \"시술 당시 나이\",\n",
    "    \"시술 유형\",\n",
    "    \"특정 시술 유형\",\n",
    "    \"배란 자극 여부\",\n",
    "    \"배란 유도 유형\",\n",
    "    \"단일 배아 이식 여부\",\n",
    "    \"착상 전 유전 검사 사용 여부\",\n",
    "    \"착상 전 유전 진단 사용 여부\",\n",
    "    \"남성 주 불임 원인\",\n",
    "    \"남성 부 불임 원인\",\n",
    "    \"여성 주 불임 원인\",\n",
    "    \"여성 부 불임 원인\",\n",
    "    \"부부 주 불임 원인\",\n",
    "    \"부부 부 불임 원인\",\n",
    "    \"불명확 불임 원인\",\n",
    "    \"불임 원인 - 난관 질환\",\n",
    "    \"불임 원인 - 남성 요인\",\n",
    "    \"불임 원인 - 배란 장애\",\n",
    "    \"불임 원인 - 여성 요인\",\n",
    "    \"불임 원인 - 자궁경부 문제\",\n",
    "    \"불임 원인 - 자궁내막증\",\n",
    "    \"불임 원인 - 정자 농도\",\n",
    "    \"불임 원인 - 정자 면역학적 요인\",\n",
    "    \"불임 원인 - 정자 운동성\",\n",
    "    \"불임 원인 - 정자 형태\",\n",
    "    \"배아 생성 주요 이유\",\n",
    "    \"총 시술 횟수\",\n",
    "    \"클리닉 내 총 시술 횟수\",\n",
    "    \"IVF 시술 횟수\",\n",
    "    \"DI 시술 횟수\",\n",
    "    \"총 임신 횟수\",\n",
    "    \"IVF 임신 횟수\",\n",
    "    \"DI 임신 횟수\",\n",
    "    \"총 출산 횟수\",\n",
    "    \"IVF 출산 횟수\",\n",
    "    \"DI 출산 횟수\",\n",
    "    \"난자 출처\",\n",
    "    \"정자 출처\",\n",
    "    \"난자 기증자 나이\",\n",
    "    \"정자 기증자 나이\",\n",
    "    \"동결 배아 사용 여부\",\n",
    "    \"신선 배아 사용 여부\",\n",
    "    \"기증 배아 사용 여부\",\n",
    "    \"대리모 여부\",\n",
    "    \"PGD 시술 여부\",\n",
    "    \"PGS 시술 여부\"\n",
    "]\n",
    "\n",
    "# 카테고리형 컬럼들을 문자열로 변환\n",
    "for col in categorical_columns:\n",
    "    X[col] = X[col].astype(str)\n",
    "    test[col] = test[col].astype(str)\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "X_train_encoded = X.copy()\n",
    "X_train_encoded[categorical_columns] = ordinal_encoder.fit_transform(X[categorical_columns])\n",
    "\n",
    "X_test_encoded = test.copy()\n",
    "X_test_encoded[categorical_columns] = ordinal_encoder.transform(test[categorical_columns])\n",
    "\n",
    "numeric_columns = [\n",
    "    \"임신 시도 또는 마지막 임신 경과 연수\",\n",
    "    \"총 생성 배아 수\",\n",
    "    \"미세주입된 난자 수\",\n",
    "    \"미세주입에서 생성된 배아 수\",\n",
    "    \"이식된 배아 수\",\n",
    "    \"미세주입 배아 이식 수\",\n",
    "    \"저장된 배아 수\",\n",
    "    \"미세주입 후 저장된 배아 수\",\n",
    "    \"해동된 배아 수\",\n",
    "    \"해동 난자 수\",\n",
    "    \"수집된 신선 난자 수\",\n",
    "    \"저장된 신선 난자 수\",\n",
    "    \"혼합된 난자 수\",\n",
    "    \"파트너 정자와 혼합된 난자 수\",\n",
    "    \"기증자 정자와 혼합된 난자 수\",\n",
    "    \"난자 채취 경과일\",\n",
    "    \"난자 해동 경과일\",\n",
    "    \"난자 혼합 경과일\",\n",
    "    \"배아 이식 경과일\",\n",
    "    \"배아 해동 경과일\"\n",
    "]\n",
    "\n",
    "X_train_encoded[numeric_columns] = X_train_encoded[numeric_columns].fillna(0)\n",
    "X_test_encoded[numeric_columns] = X_test_encoded[numeric_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4befc12e-de89-47ce-8b1f-395190498878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5508\n",
      "F1 Score: 0.2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py:61: UserWarning: Glyph 49892 (\\N{HANGUL SYLLABLE SIL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py:61: UserWarning: Glyph 54056 (\\N{HANGUL SYLLABLE PAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py:61: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py:61: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49892 (\\N{HANGUL SYLLABLE SIL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51228 (\\N{HANGUL SYLLABLE JE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44050 (\\N{HANGUL SYLLABLE GABS}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50696 (\\N{HANGUL SYLLABLE YE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 52769 (\\N{HANGUL SYLLABLE CEUG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54056 (\\N{HANGUL SYLLABLE PAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49457 (\\N{HANGUL SYLLABLE SEONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "C:\\Users\\pung\\anaconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44277 (\\N{HANGUL SYLLABLE GONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# 데이터 분할 (8:2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_encoded, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 언더샘플링 함수\n",
    "def undersample(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    class_counts = df['임신 성공 여부'].value_counts()\n",
    "    min_count = class_counts.min()\n",
    "    \n",
    "    df_balanced = pd.concat([\n",
    "        resample(df[df['임신 성공 여부'] == 0], replace=False, n_samples=min_count, random_state=42),\n",
    "        resample(df[df['임신 성공 여부'] == 1], replace=False, n_samples=min_count, random_state=42)\n",
    "    ])\n",
    "    \n",
    "    return df_balanced.drop(columns=['임신 성공 여부']), df_balanced['임신 성공 여부']\n",
    "\n",
    "# 검증 데이터 언더샘플링\n",
    "X_val_balanced, y_val_balanced = undersample(X_val, y_val)\n",
    "\n",
    "# 개별 모델 정의\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "et_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# 앙상블 (Voting Classifier)\n",
    "ensemble_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_clf),\n",
    "        ('et', et_clf),\n",
    "        ('gb', gb_clf)\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "ensemble_clf.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터 예측\n",
    "y_pred = ensemble_clf.predict(X_val_balanced)\n",
    "\n",
    "# 성능 평가\n",
    "accuracy = accuracy_score(y_val_balanced, y_pred)\n",
    "f1 = f1_score(y_val_balanced, y_pred)\n",
    "cm = confusion_matrix(y_val_balanced, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# 컨퓨전 매트릭스 시각화\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['실패', '성공'], yticklabels=['실패', '성공'])\n",
    "plt.xlabel('예측값')\n",
    "plt.ylabel('실제값')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5265f180-8be7-4e84-b9b6-d80d7c8e3f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 53102, number of negative: 151978\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051521\n",
      "[LightGBM] [Info] Start training from score -1.051521\n",
      "Confusion Matrix\n",
      "[[35899  2246]\n",
      " [11039  2087]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84     38145\n",
      "           1       0.48      0.16      0.24     13126\n",
      "\n",
      "    accuracy                           0.74     51271\n",
      "   macro avg       0.62      0.55      0.54     51271\n",
      "weighted avg       0.69      0.74      0.69     51271\n",
      "\n",
      "예측 결과가 'baseline_submit.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 전처리된 훈련 데이터와 테스트 데이터를 파일에서 로드\n",
    "X_train_encoded = pd.read_csv('../data/train_encoded.csv')\n",
    "X_test_encoded = pd.read_csv('../data/test_encoded.csv')\n",
    "\n",
    "# 타겟 변수와 특성 분리\n",
    "y = X_train_encoded['임신 성공 여부']\n",
    "X = X_train_encoded.drop('임신 성공 여부', axis=1)\n",
    "\n",
    "# 훈련 데이터 나누기\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 정의 (여러 모델을 사용)\n",
    "et_model = ExtraTreesClassifier(random_state=42)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# 앙상블 모델 정의 (Voting Classifier)\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('et', et_model),\n",
    "    ('rf', rf_model),\n",
    "    ('xgb', xgb_model),\n",
    "    ('lgb', lgb_model)\n",
    "], voting='soft')  # soft voting: 예측 확률의 평균으로 최종 예측\n",
    "\n",
    "# 모델 학습\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = voting_model.predict(X_val)\n",
    "y_pred_proba = voting_model.predict_proba(X_val)[:, 1]  # 예측 확률\n",
    "\n",
    "# 성능 평가\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"\\nClassification Report\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# 예측 결과를 sample_submission 파일에 저장\n",
    "pred_proba = voting_model.predict_proba(X_test_encoded)[:, 1]\n",
    "sample_submission = pd.read_csv('../submission/sample_submission.csv')\n",
    "sample_submission['probability'] = pred_proba\n",
    "\n",
    "# 제출 파일로 저장\n",
    "sample_submission.to_csv('../submission/baseline_submit.csv', index=False)\n",
    "\n",
    "print(\"예측 결과가 'baseline_submit.csv'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d269dd-6f76-4d07-8b77-15774232b5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 53102, number of negative: 151978\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 716\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258933 -> initscore=-1.051521\n",
      "[LightGBM] [Info] Start training from score -1.051521\n",
      "Confusion Matrix\n",
      "[[12359   767]\n",
      " [11039  2087]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.94      0.68     13126\n",
      "           1       0.73      0.16      0.26     13126\n",
      "\n",
      "    accuracy                           0.55     26252\n",
      "   macro avg       0.63      0.55      0.47     26252\n",
      "weighted avg       0.63      0.55      0.47     26252\n",
      "\n",
      "예측 결과가 'baseline_submit.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 전처리된 훈련 데이터와 테스트 데이터를 파일에서 로드\n",
    "X_train_encoded = pd.read_csv('../data/train_encoded.csv')\n",
    "X_test_encoded = pd.read_csv('../data/test_encoded.csv')\n",
    "\n",
    "# 타겟 변수와 특성 분리\n",
    "y = X_train_encoded['임신 성공 여부']\n",
    "X = X_train_encoded.drop('임신 성공 여부', axis=1)\n",
    "\n",
    "# 훈련 데이터 나누기\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 언더샘플링 함수\n",
    "def undersample(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    class_counts = df['임신 성공 여부'].value_counts()\n",
    "    min_count = class_counts.min()\n",
    "    \n",
    "    df_balanced = pd.concat([\n",
    "        resample(df[df['임신 성공 여부'] == 0], replace=False, n_samples=min_count, random_state=42),\n",
    "        resample(df[df['임신 성공 여부'] == 1], replace=False, n_samples=min_count, random_state=42)\n",
    "    ])\n",
    "    \n",
    "    return df_balanced.drop(columns=['임신 성공 여부']), df_balanced['임신 성공 여부']\n",
    "\n",
    "# 검증 데이터 언더샘플링\n",
    "X_val, y_val = undersample(X_val, y_val)\n",
    "\n",
    "# 모델 정의 (여러 모델을 사용)\n",
    "et_model = ExtraTreesClassifier(random_state=42)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# 앙상블 모델 정의 (Voting Classifier)\n",
    "voting_model = VotingClassifier(estimators=[\n",
    "    ('et', et_model),\n",
    "    ('rf', rf_model),\n",
    "    ('xgb', xgb_model),\n",
    "    ('lgb', lgb_model)\n",
    "], voting='soft')  # soft voting: 예측 확률의 평균으로 최종 예측\n",
    "\n",
    "# 모델 학습\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = voting_model.predict(X_val)\n",
    "y_pred_proba = voting_model.predict_proba(X_val)[:, 1]  # 예측 확률\n",
    "\n",
    "# 성능 평가\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(\"\\nClassification Report\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# 예측 결과를 sample_submission 파일에 저장\n",
    "pred_proba = voting_model.predict_proba(X_test_encoded)[:, 1]\n",
    "sample_submission = pd.read_csv('../submission/sample_submission.csv')\n",
    "sample_submission['probability'] = pred_proba\n",
    "\n",
    "# 제출 파일로 저장\n",
    "sample_submission.to_csv('../submission/baseline_submit.csv', index=False)\n",
    "\n",
    "print(\"예측 결과가 'baseline_submit.csv'에 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
