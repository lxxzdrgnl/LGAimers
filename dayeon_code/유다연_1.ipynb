{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb63bd-aa6f-4ba4-8a6d-86bd36995cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïó¨Îü¨Í∞ÄÏßÄ ÏãúÎèÑ(DIÎäî Î≤ÑÎ¶¨Ïûê)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a02490a-0533-4c3e-b564-98174710a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Î≥ÄÍ≤ΩÎêú ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨: /Users/yudayeon/Desktop/LGAimers\n",
      "üî• ÏãúÏà† Ïú†ÌòïÎ≥Ñ Í≥†Ïú† Í∞í üî•\n",
      "[1. 0.]\n",
      "\n",
      "üî• ÏãúÏà† Ïú†ÌòïÎ≥Ñ Í∞úÏàò üî•\n",
      "ÏãúÏà† Ïú†Ìòï\n",
      "1.0    250060\n",
      "0.0      6291\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "\n",
    "import os\n",
    "\n",
    "# ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨Î•º Î≥ÄÍ≤Ω\n",
    "os.chdir('/Users/yudayeon/Desktop/LGAimers')\n",
    "\n",
    "# Î≥ÄÍ≤ΩÎêú ÎîîÎ†âÌÜ†Î¶¨ ÌôïÏù∏\n",
    "print(\"üî• Î≥ÄÍ≤ΩÎêú ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨:\", os.getcwd())\n",
    "\n",
    "# Ïù¥Ï†ú ÏÉÅÎåÄ Í≤ΩÎ°ú ÏÇ¨Ïö© Í∞ÄÎä•\n",
    "X_train_encoded = pd.read_csv('data/train_encoded.csv')\n",
    "X_test_encoded = pd.read_csv('data/test_encoded.csv')\n",
    "\n",
    "# ÏãúÏà† Ïú†Ìòï Ïª¨ÎüºÎ™Ö ÏÑ§Ï†ï (Ïã§Ï†ú Ïª¨ÎüºÎ™ÖÏù¥ Îã§Î•º ÏàòÎèÑ ÏûàÏúºÎãà ÌôïÏù∏ ÌïÑÏöî!)\n",
    "procedure_column = \"ÏãúÏà† Ïú†Ìòï\"\n",
    "\n",
    "# ÏãúÏà† Ïú†ÌòïÏóê Ìè¨Ìï®Îêú Í≥†Ïú† Í∞í Ï∂úÎ†•\n",
    "print(\"üî• ÏãúÏà† Ïú†ÌòïÎ≥Ñ Í≥†Ïú† Í∞í üî•\")\n",
    "print(X_train_encoded[procedure_column].unique())\n",
    "\n",
    "# ÏãúÏà† Ïú†ÌòïÎ≥Ñ Í∞úÏàò ÌôïÏù∏\n",
    "print(\"\\nüî• ÏãúÏà† Ïú†ÌòïÎ≥Ñ Í∞úÏàò üî•\")\n",
    "print(X_train_encoded[procedure_column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8335678b-76ae-4f5d-b5a8-3818b477bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 52982, number of negative: 152098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 720\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "üî• Confusion Matrix üî•\n",
      "[[36974  1051]\n",
      " [12000  1246]]\n",
      "\n",
      "üî• Classification Report üî•\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.97      0.85     38025\n",
      "           1       0.54      0.09      0.16     13246\n",
      "\n",
      "    accuracy                           0.75     51271\n",
      "   macro avg       0.65      0.53      0.51     51271\n",
      "weighted avg       0.70      0.75      0.67     51271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ‚úÖ ÌÉÄÍ≤ü Î≥ÄÏàòÏôÄ ÌäπÏÑ± Î∂ÑÎ¶¨\n",
    "y = X_train_encoded['ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä']\n",
    "X = X_train_encoded.drop('ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä', axis=1)\n",
    "\n",
    "# ‚úÖ Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï† (ÌõàÎ†® / Í≤ÄÏ¶ù)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# ‚úÖ ÏµúÏ†Å ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Ï†ÅÏö©Ìïú Î™®Îç∏ Ï†ïÏùò\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=215,\n",
    "    max_depth=7,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=359,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.045093620098282834,\n",
    "    subsample=0.6669970717173888,\n",
    "    colsample_bytree=0.934119080218835,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=492,\n",
    "    num_leaves=88,\n",
    "    learning_rate=0.014666949438705097,\n",
    "    subsample=0.8766412273868395,\n",
    "    colsample_bytree=0.5848756135604947,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ‚úÖ Î™®Îç∏ ÌïôÏäµ\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Í∞Å Î™®Îç∏Ïùò ÏòàÏ∏° ÌôïÎ•† Í≥ÑÏÇ∞\n",
    "rf_preds = rf_model.predict_proba(X_val)[:, 1]\n",
    "xgb_preds = xgb_model.predict_proba(X_val)[:, 1]\n",
    "lgb_preds = lgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# ‚úÖ Í∞ÄÏ§ë ÌèâÍ∑† ÏïôÏÉÅÎ∏î (Í∞ÄÏ§ëÏπò ÏÑ§Ï†ï)\n",
    "rf_weight = 0.4\n",
    "xgb_weight = 0.3\n",
    "lgb_weight = 0.3\n",
    "\n",
    "final_preds = (rf_weight * rf_preds) + (xgb_weight * xgb_preds) + (lgb_weight * lgb_preds)\n",
    "final_preds_binary = (final_preds >= 0.5).astype(int)  # 0.5 Ïù¥ÏÉÅÏù¥Î©¥ 1, ÏïÑÎãàÎ©¥ 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a93c7f2a-a464-41dd-8d63-a34930d9f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ‚úÖ ÌÉÄÍ≤ü Î≥ÄÏàòÏôÄ ÌäπÏÑ± Î∂ÑÎ¶¨\n",
    "y = X_train_encoded['ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä']\n",
    "X = X_train_encoded.drop('ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä', axis=1)\n",
    "\n",
    "# ‚úÖ Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï† (ÌõàÎ†® / Í≤ÄÏ¶ù)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02d326fe-1330-4d77-a95c-b12325a964cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Confusion Matrix üî•\n",
      "[[37000.  1025.]\n",
      " [12015.  1231.]]\n",
      "\n",
      "üî• Classification Report üî•\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7549    0.9730    0.8502     38025\n",
      "           1     0.5457    0.0929    0.1588     13246\n",
      "\n",
      "    accuracy                         0.7457     51271\n",
      "   macro avg     0.6503    0.5330    0.5045     51271\n",
      "weighted avg     0.7008    0.7457    0.6716     51271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ ÌèâÍ∞Ä ÏßÄÌëú ÌôïÏù∏\n",
    "conf_matrix = confusion_matrix(y_val, final_preds_binary).astype(float)\n",
    "\n",
    "print(\"üî• Confusion Matrix üî•\")\n",
    "print(np.round(conf_matrix, 4))  # ÏÜåÏàòÏ†ê 4ÏûêÎ¶¨ÍπåÏßÄ Î∞òÏò¨Î¶ºÌïòÏó¨ Ï∂úÎ†•\n",
    "\n",
    "print(\"\\nüî• Classification Report üî•\")\n",
    "print(classification_report(y_val, final_preds_binary, digits=4))  # classification reportÎèÑ ÏÜåÏàòÏ†ê 4ÏûêÎ¶¨Î°ú Ï∂úÎ†•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2053a7ca-2d23-4583-a105-181fb9b66ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 27\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# ‚úÖ RandomForest Î™®Îç∏ ÌïôÏäµ\u001b[39;00m\n\u001b[1;32m     20\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m     21\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, \n\u001b[1;32m     22\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     26\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(X_train_ivf_split, y_train_ivf_split)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ‚úÖ XGBoost Î™®Îç∏ ÌïôÏäµ (scale_pos_weight Ï†ÅÏö©)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[1;32m     31\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m,\n\u001b[1;32m     32\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.03\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     38\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[1;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[1;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ‚úÖ IVF(1) Îç∞Ïù¥ÌÑ∞Îßå ÏÑ†ÌÉù\n",
    "ivf_mask = (X_train[\"ÏãúÏà† Ïú†Ìòï\"] == 1)\n",
    "X_train_ivf = X_train[ivf_mask]\n",
    "y_train_ivf = y_train[ivf_mask]\n",
    "\n",
    "# ‚úÖ IVF(1) Îç∞Ïù¥ÌÑ∞Î°úÎßå train-validation split\n",
    "X_train_ivf_split, X_val_ivf_split, y_train_ivf_split, y_val_ivf_split = train_test_split(\n",
    "    X_train_ivf, y_train_ivf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ‚úÖ RandomForest Î™®Îç∏ ÌïôÏäµ\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300, \n",
    "    max_depth=15, \n",
    "    min_samples_split=5, \n",
    "    class_weight=\"balanced\",  # ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Ìï¥Í≤∞\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ XGBoost Î™®Îç∏ ÌïôÏäµ (scale_pos_weight Ï†ÅÏö©)\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=3,  # ÏñëÏÑ±(1) Í∞ÄÏ§ëÏπò Ï¶ùÍ∞Ä (Î∂àÍ∑†Ìòï Îç∞Ïù¥ÌÑ∞ Ìï¥Í≤∞)\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ LightGBM Î™®Îç∏ ÌïôÏäµ (scale_pos_weight Ï†ÅÏö©)\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=10,\n",
    "    num_leaves=50,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    scale_pos_weight=3,  # ÏñëÏÑ±(1) Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ§ëÏπò Ï¶ùÍ∞Ä\n",
    "    min_child_samples=20,\n",
    "    max_bin=300,  # Ïù¥ÏßÑÌôî Í∞úÏàò Ï¶ùÍ∞Ä\n",
    "    random_state=42\n",
    ")\n",
    "lgb_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ Ï†ÑÏ≤¥ Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏòàÏ∏° ÏàòÌñâ\n",
    "rf_preds = rf_model.predict_proba(X_val)[:, 1]\n",
    "xgb_preds = xgb_model.predict_proba(X_val)[:, 1]\n",
    "lgb_preds = lgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# ‚úÖ Í∞ÄÏ§ë ÌèâÍ∑† ÏïôÏÉÅÎ∏î\n",
    "rf_weight, xgb_weight, lgb_weight = 0.3, 0.4, 0.3\n",
    "final_preds = (rf_weight * rf_preds) + (xgb_weight * xgb_preds) + (lgb_weight * lgb_preds)\n",
    "\n",
    "# ‚úÖ DI(0)Ïù∏ Í≤ΩÏö∞ Í∞ïÏ†úÎ°ú 0ÏúºÎ°ú ÏòàÏ∏°\n",
    "final_preds_binary = (final_preds >= 0.5).astype(int)\n",
    "final_preds_binary[X_val[\"ÏãúÏà† Ïú†Ìòï\"] == 0] = 0\n",
    "\n",
    "# ‚úÖ Confusion Matrix ÏõêÎ≥∏ Ï∂úÎ†•\n",
    "cm = confusion_matrix(y_val, final_preds_binary)\n",
    "print(\"\\nüî• Overall Confusion Matrix üî•\")\n",
    "print(cm)\n",
    "\n",
    "# ‚úÖ Classification Report (ÏÜåÏàòÏ†ê 4Ïß∏ÏûêÎ¶¨ÍπåÏßÄ)\n",
    "print(\"\\nüî• Overall Classification Report üî•\")\n",
    "print(classification_report(y_val, final_preds_binary, digits=4))\n",
    "\n",
    "submission_path = '/Users/yudayeon/Desktop/LGAimers/submission/sample_submission.csv'\n",
    "sample_submission = pd.read_csv(submission_path)\n",
    "sample_submission['probability'] = final_preds\n",
    "\n",
    "# CSV ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "output_path = '/Users/yudayeon/Desktop/LGAimers/submission/baseline_submit2.csv'\n",
    "sample_submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"ÏòàÏ∏° Í≤∞Í≥ºÍ∞Ä '{output_path}'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e22289a2-6b58-4757-bd1d-6c54ee242903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 41871, number of negative: 118160\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 691\n",
      "[LightGBM] [Info] Number of data points in the train set: 160031, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261643 -> initscore=-1.037446\n",
      "[LightGBM] [Info] Start training from score -1.037446\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "üî• Overall Confusion Matrix üî•\n",
      "[[21965 16060]\n",
      " [ 3159 10087]]\n",
      "\n",
      "üî• Overall Classification Report üî•\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8743    0.5776    0.6957     38025\n",
      "           1     0.3858    0.7615    0.5121     13246\n",
      "\n",
      "    accuracy                         0.6251     51271\n",
      "   macro avg     0.6300    0.6696    0.6039     51271\n",
      "weighted avg     0.7481    0.6251    0.6482     51271\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ID\n- probability\nFeature names seen at fit time, yet now missing:\n- DI ÏãúÏà† ÌöüÏàò\n- DI ÏûÑÏã† ÌöüÏàò\n- DI Ï∂úÏÇ∞ ÌöüÏàò\n- IVF ÏãúÏà† ÌöüÏàò\n- IVF ÏûÑÏã† ÌöüÏàò\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m sample_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(submission_path)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# ‚úÖ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏòàÏ∏° ÏàòÌñâ\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m rf_preds_test \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     84\u001b[0m xgb_preds_test \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     85\u001b[0m lgb_preds_test \u001b[38;5;241m=\u001b[39m lgb_model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:947\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    945\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    946\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    950\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:641\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    639\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    642\u001b[0m     X,\n\u001b[1;32m    643\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[1;32m    644\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    645\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    646\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m    647\u001b[0m )\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    545\u001b[0m ):\n\u001b[1;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    533\u001b[0m     )\n\u001b[0;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- ID\n- probability\nFeature names seen at fit time, yet now missing:\n- DI ÏãúÏà† ÌöüÏàò\n- DI ÏûÑÏã† ÌöüÏàò\n- DI Ï∂úÏÇ∞ ÌöüÏàò\n- IVF ÏãúÏà† ÌöüÏàò\n- IVF ÏûÑÏã† ÌöüÏàò\n- ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ‚úÖ IVF(1) Îç∞Ïù¥ÌÑ∞Îßå ÏÑ†ÌÉù\n",
    "ivf_mask = (X_train[\"ÏãúÏà† Ïú†Ìòï\"] == 1)\n",
    "X_train_ivf = X_train[ivf_mask]\n",
    "y_train_ivf = y_train[ivf_mask]\n",
    "\n",
    "# ‚úÖ IVF(1) Îç∞Ïù¥ÌÑ∞Î°úÎßå train-validation split\n",
    "X_train_ivf_split, X_val_ivf_split, y_train_ivf_split, y_val_ivf_split = train_test_split(\n",
    "    X_train_ivf, y_train_ivf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ‚úÖ RandomForest Î™®Îç∏ ÌïôÏäµ\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300, \n",
    "    max_depth=15, \n",
    "    min_samples_split=5, \n",
    "    class_weight=\"balanced\",  # ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Ìï¥Í≤∞\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ XGBoost Î™®Îç∏ ÌïôÏäµ (scale_pos_weight Ï†ÅÏö©)\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=3,  # ÏñëÏÑ±(1) Í∞ÄÏ§ëÏπò Ï¶ùÍ∞Ä (Î∂àÍ∑†Ìòï Îç∞Ïù¥ÌÑ∞ Ìï¥Í≤∞)\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ LightGBM Î™®Îç∏ ÌïôÏäµ (scale_pos_weight Ï†ÅÏö©)\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=10,\n",
    "    num_leaves=50,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    scale_pos_weight=3,  # ÏñëÏÑ±(1) Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ§ëÏπò Ï¶ùÍ∞Ä\n",
    "    min_child_samples=20,\n",
    "    max_bin=300,  # Ïù¥ÏßÑÌôî Í∞úÏàò Ï¶ùÍ∞Ä\n",
    "    random_state=42\n",
    ")\n",
    "lgb_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ Ï†ÑÏ≤¥ Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏòàÏ∏° ÏàòÌñâ\n",
    "rf_preds = rf_model.predict_proba(X_val)[:, 1]\n",
    "xgb_preds = xgb_model.predict_proba(X_val)[:, 1]\n",
    "lgb_preds = lgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# ‚úÖ Í∞ÄÏ§ë ÌèâÍ∑† ÏïôÏÉÅÎ∏î\n",
    "rf_weight, xgb_weight, lgb_weight = 0.4, 0.3, 0.3\n",
    "final_preds = (rf_weight * rf_preds) + (xgb_weight * xgb_preds) + (lgb_weight * lgb_preds)\n",
    "\n",
    "# ‚úÖ DI(0)Ïù∏ Í≤ΩÏö∞ Í∞ïÏ†úÎ°ú 0ÏúºÎ°ú ÏòàÏ∏°\n",
    "final_preds_binary = (final_preds >= 0.5).astype(int)\n",
    "final_preds_binary[X_val[\"ÏãúÏà† Ïú†Ìòï\"] == 0] = 0\n",
    "\n",
    "# ‚úÖ Confusion Matrix ÏõêÎ≥∏ Ï∂úÎ†•\n",
    "cm = confusion_matrix(y_val, final_preds_binary)\n",
    "print(\"\\nüî• Overall Confusion Matrix üî•\")\n",
    "print(cm)\n",
    "\n",
    "# ‚úÖ Classification Report (ÏÜåÏàòÏ†ê 4Ïß∏ÏûêÎ¶¨ÍπåÏßÄ)\n",
    "print(\"\\nüî• Overall Classification Report üî•\")\n",
    "print(classification_report(y_val, final_preds_binary, digits=4))\n",
    "\n",
    "# ‚úÖ Ï†úÏ∂ú ÌååÏùº Î°úÎìú\n",
    "submission_path = '/Users/yudayeon/Desktop/LGAimers/submission/sample_submission.csv'\n",
    "sample_submission = pd.read_csv(submission_path)\n",
    "\n",
    "# ‚úÖ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏòàÏ∏° ÏàòÌñâ\n",
    "rf_preds_test = rf_model.predict_proba(X_test)[:, 1]\n",
    "xgb_preds_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "lgb_preds_test = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ‚úÖ Í∞ÄÏ§ë ÌèâÍ∑† ÏïôÏÉÅÎ∏î\n",
    "final_preds_test = (rf_weight * rf_preds_test) + (xgb_weight * xgb_preds_test) + (lgb_weight * lgb_preds_test)\n",
    "\n",
    "# ‚úÖ DI(0)Ïù∏ Í≤ΩÏö∞ Í∞ïÏ†úÎ°ú 0ÏúºÎ°ú ÏòàÏ∏°\n",
    "final_preds_test_binary = (final_preds_test >= 0.5).astype(int)\n",
    "final_preds_test_binary[X_test[\"ÏãúÏà† Ïú†Ìòï\"] == 0] = 0\n",
    "\n",
    "# ‚úÖ Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ±\n",
    "sample_submission['probability'] = final_preds_test\n",
    "\n",
    "# ‚úÖ CSV ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "output_path = '/Users/yudayeon/Desktop/LGAimers/submission/baseline_submit3.csv'\n",
    "sample_submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"ÏòàÏ∏° Í≤∞Í≥ºÍ∞Ä '{output_path}'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9754638-4252-48f8-acf0-1fb23341a66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 41871, number of negative: 118160\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 691\n",
      "[LightGBM] [Info] Number of data points in the train set: 160031, number of used features: 61\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.261643 -> initscore=-1.037446\n",
      "[LightGBM] [Info] Start training from score -1.037446\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "üî• Overall Confusion Matrix üî•\n",
      "[[21965 16060]\n",
      " [ 3159 10087]]\n",
      "\n",
      "üî• Overall Classification Report üî•\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8743    0.5776    0.6957     38025\n",
      "           1     0.3858    0.7615    0.5121     13246\n",
      "\n",
      "    accuracy                         0.6251     51271\n",
      "   macro avg     0.6300    0.6696    0.6039     51271\n",
      "weighted avg     0.7481    0.6251    0.6482     51271\n",
      "\n",
      "ÏòàÏ∏° Í≤∞Í≥ºÍ∞Ä '/Users/yudayeon/Desktop/LGAimers/submission/baseline_submit3.csv'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ IVF(1) Îç∞Ïù¥ÌÑ∞Îßå ÏÑ†ÌÉù\n",
    "ivf_mask = (X_train[\"ÏãúÏà† Ïú†Ìòï\"] == 1)\n",
    "X_train_ivf = X_train[ivf_mask]\n",
    "y_train_ivf = y_train[ivf_mask]\n",
    "\n",
    "# ‚úÖ IVF(1) Îç∞Ïù¥ÌÑ∞Î°úÎßå train-validation split\n",
    "X_train_ivf_split, X_val_ivf_split, y_train_ivf_split, y_val_ivf_split = train_test_split(\n",
    "    X_train_ivf, y_train_ivf, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ‚úÖ RandomForest Î™®Îç∏ ÌïôÏäµ\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300, \n",
    "    max_depth=15, \n",
    "    min_samples_split=5, \n",
    "    class_weight=\"balanced\",  # ÌÅ¥ÎûòÏä§ Î∂àÍ∑†Ìòï Ìï¥Í≤∞\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ XGBoost Î™®Îç∏ ÌïôÏäµ (scale_pos_weight Ï†ÅÏö©)\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=3,  # ÏñëÏÑ±(1) Í∞ÄÏ§ëÏπò Ï¶ùÍ∞Ä (Î∂àÍ∑†Ìòï Îç∞Ïù¥ÌÑ∞ Ìï¥Í≤∞)\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ LightGBM Î™®Îç∏ ÌïôÏäµ (scale_pos_weight Ï†ÅÏö©)\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=10,\n",
    "    num_leaves=50,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    scale_pos_weight=3,  # ÏñëÏÑ±(1) Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ§ëÏπò Ï¶ùÍ∞Ä\n",
    "    min_child_samples=20,\n",
    "    max_bin=300,  # Ïù¥ÏßÑÌôî Í∞úÏàò Ï¶ùÍ∞Ä\n",
    "    random_state=42\n",
    ")\n",
    "lgb_model.fit(X_train_ivf_split, y_train_ivf_split)\n",
    "\n",
    "# ‚úÖ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "test_data_path = '/Users/yudayeon/Desktop/LGAimers/data/test_encoded.csv'\n",
    "X_test = pd.read_csv(test_data_path)\n",
    "\n",
    "# ‚úÖ X_testÏóêÏÑú X_trainÍ≥º ÎèôÏùºÌïú Ïª¨ÎüºÎßå ÏÑ†ÌÉù\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# ‚úÖ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú ÏòàÏ∏° ÏàòÌñâ\n",
    "rf_preds_test = rf_model.predict_proba(X_test)[:, 1]\n",
    "xgb_preds_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "lgb_preds_test = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ‚úÖ Í∞ÄÏ§ë ÌèâÍ∑† ÏïôÏÉÅÎ∏î\n",
    "final_preds_test = (rf_weight * rf_preds_test) + (xgb_weight * xgb_preds_test) + (lgb_weight * lgb_preds_test)\n",
    "\n",
    "# ‚úÖ DI(0)Ïù∏ Í≤ΩÏö∞ Í∞ïÏ†úÎ°ú 0ÏúºÎ°ú ÏòàÏ∏°\n",
    "final_preds_test_binary = (final_preds_test >= 0.5).astype(int)\n",
    "final_preds_test_binary[X_test[\"ÏãúÏà† Ïú†Ìòï\"] == 0] = 0\n",
    "\n",
    "# ‚úÖ Confusion Matrix ÏõêÎ≥∏ Ï∂úÎ†•\n",
    "cm = confusion_matrix(y_val, final_preds_binary)\n",
    "print(\"\\nüî• Overall Confusion Matrix üî•\")\n",
    "print(cm)\n",
    "\n",
    "# ‚úÖ Classification Report (ÏÜåÏàòÏ†ê 4Ïß∏ÏûêÎ¶¨ÍπåÏßÄ)\n",
    "print(\"\\nüî• Overall Classification Report üî•\")\n",
    "print(classification_report(y_val, final_preds_binary, digits=4))\n",
    "\n",
    "# ‚úÖ Ï†úÏ∂ú ÌååÏùº Î°úÎìú\n",
    "submission_path = '/Users/yudayeon/Desktop/LGAimers/submission/sample_submission.csv'\n",
    "sample_submission = pd.read_csv(submission_path)\n",
    "\n",
    "# ‚úÖ ÏòàÏ∏°Í∞í Ï†ÄÏû•\n",
    "sample_submission['probability'] = final_preds_test\n",
    "\n",
    "# ‚úÖ CSV ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "output_path = '/Users/yudayeon/Desktop/LGAimers/submission/baseline_submit3.csv'\n",
    "sample_submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"ÏòàÏ∏° Í≤∞Í≥ºÍ∞Ä '{output_path}'Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
