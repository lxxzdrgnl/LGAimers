{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb63bd-aa6f-4ba4-8a6d-86bd36995cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ê°€ì§€ ì‹œë„(DIëŠ” ë²„ë¦¬ì)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a02490a-0533-4c3e-b564-98174710a1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ ë³€ê²½ëœ ì‘ì—… ë””ë ‰í† ë¦¬: /Users/yudayeon/Desktop/LGAimers\n",
      "ğŸ”¥ ì‹œìˆ  ìœ í˜•ë³„ ê³ ìœ  ê°’ ğŸ”¥\n",
      "[1. 0.]\n",
      "\n",
      "ğŸ”¥ ì‹œìˆ  ìœ í˜•ë³„ ê°œìˆ˜ ğŸ”¥\n",
      "ì‹œìˆ  ìœ í˜•\n",
      "1.0    250060\n",
      "0.0      6291\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import optuna\n",
    "\n",
    "import os\n",
    "\n",
    "# ì‘ì—… ë””ë ‰í† ë¦¬ë¥¼ ë³€ê²½\n",
    "os.chdir('/Users/yudayeon/Desktop/LGAimers')\n",
    "\n",
    "# ë³€ê²½ëœ ë””ë ‰í† ë¦¬ í™•ì¸\n",
    "print(\"ğŸ”¥ ë³€ê²½ëœ ì‘ì—… ë””ë ‰í† ë¦¬:\", os.getcwd())\n",
    "\n",
    "# ì´ì œ ìƒëŒ€ ê²½ë¡œ ì‚¬ìš© ê°€ëŠ¥\n",
    "X_train_encoded = pd.read_csv('data/train_encoded.csv')\n",
    "X_test_encoded = pd.read_csv('data/test_encoded.csv')\n",
    "\n",
    "# ì‹œìˆ  ìœ í˜• ì»¬ëŸ¼ëª… ì„¤ì • (ì‹¤ì œ ì»¬ëŸ¼ëª…ì´ ë‹¤ë¥¼ ìˆ˜ë„ ìˆìœ¼ë‹ˆ í™•ì¸ í•„ìš”!)\n",
    "procedure_column = \"ì‹œìˆ  ìœ í˜•\"\n",
    "\n",
    "# ì‹œìˆ  ìœ í˜•ì— í¬í•¨ëœ ê³ ìœ  ê°’ ì¶œë ¥\n",
    "print(\"ğŸ”¥ ì‹œìˆ  ìœ í˜•ë³„ ê³ ìœ  ê°’ ğŸ”¥\")\n",
    "print(X_train_encoded[procedure_column].unique())\n",
    "\n",
    "# ì‹œìˆ  ìœ í˜•ë³„ ê°œìˆ˜ í™•ì¸\n",
    "print(\"\\nğŸ”¥ ì‹œìˆ  ìœ í˜•ë³„ ê°œìˆ˜ ğŸ”¥\")\n",
    "print(X_train_encoded[procedure_column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8335678b-76ae-4f5d-b5a8-3818b477bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 52982, number of negative: 152098\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031973 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 720\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "ğŸ”¥ Confusion Matrix ğŸ”¥\n",
      "[[36974  1051]\n",
      " [12000  1246]]\n",
      "\n",
      "ğŸ”¥ Classification Report ğŸ”¥\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.97      0.85     38025\n",
      "           1       0.54      0.09      0.16     13246\n",
      "\n",
      "    accuracy                           0.75     51271\n",
      "   macro avg       0.65      0.53      0.51     51271\n",
      "weighted avg       0.70      0.75      0.67     51271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# âœ… íƒ€ê²Ÿ ë³€ìˆ˜ì™€ íŠ¹ì„± ë¶„ë¦¬\n",
    "y = X_train_encoded['ì„ì‹  ì„±ê³µ ì—¬ë¶€']\n",
    "X = X_train_encoded.drop('ì„ì‹  ì„±ê³µ ì—¬ë¶€', axis=1)\n",
    "\n",
    "# âœ… ë°ì´í„° ë¶„í•  (í›ˆë ¨ / ê²€ì¦)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# âœ… ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©í•œ ëª¨ë¸ ì •ì˜\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=215,\n",
    "    max_depth=7,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=8,\n",
    "    max_features=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=359,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.045093620098282834,\n",
    "    subsample=0.6669970717173888,\n",
    "    colsample_bytree=0.934119080218835,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=492,\n",
    "    num_leaves=88,\n",
    "    learning_rate=0.014666949438705097,\n",
    "    subsample=0.8766412273868395,\n",
    "    colsample_bytree=0.5848756135604947,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# âœ… ëª¨ë¸ í•™ìŠµ\n",
    "rf_model.fit(X_train, y_train)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# âœ… ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°\n",
    "rf_preds = rf_model.predict_proba(X_val)[:, 1]\n",
    "xgb_preds = xgb_model.predict_proba(X_val)[:, 1]\n",
    "lgb_preds = lgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# âœ… ê°€ì¤‘ í‰ê·  ì•™ìƒë¸” (ê°€ì¤‘ì¹˜ ì„¤ì •)\n",
    "rf_weight = 0.4\n",
    "xgb_weight = 0.3\n",
    "lgb_weight = 0.3\n",
    "\n",
    "final_preds = (rf_weight * rf_preds) + (xgb_weight * xgb_preds) + (lgb_weight * lgb_preds)\n",
    "final_preds_binary = (final_preds >= 0.5).astype(int)  # 0.5 ì´ìƒì´ë©´ 1, ì•„ë‹ˆë©´ 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a93c7f2a-a464-41dd-8d63-a34930d9f760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ë°ì´í„° ìˆ˜ (IVF=1): 200045\n",
      "Validation ë°ì´í„° ìˆ˜: 51271\n",
      "\n",
      "ğŸ”¥ Validation Set Performance ğŸ”¥\n",
      "\n",
      "ğŸ”¥ Confusion Matrix ğŸ”¥\n",
      "[[37581   564]\n",
      " [12420   706]]\n",
      "\n",
      "ğŸ”¥ Classification Report ğŸ”¥\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7516    0.9852    0.8527     38145\n",
      "           1     0.5559    0.0538    0.0981     13126\n",
      "\n",
      "    accuracy                         0.7468     51271\n",
      "   macro avg     0.6538    0.5195    0.4754     51271\n",
      "weighted avg     0.7015    0.7468    0.6595     51271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# âœ… ê¸°ì¡´ ì¸ì½”ë”©ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "X_train_encoded = pd.read_csv('data/train_encoded.csv')\n",
    "X_test_encoded = pd.read_csv('data/test_encoded.csv')\n",
    "\n",
    "# âœ… Target ë³€ìˆ˜ ë¶„ë¦¬\n",
    "y_train = X_train_encoded[\"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"]  # 'target' ì»¬ëŸ¼ì„ ì •ë‹µ ë ˆì´ë¸”ë¡œ ì„¤ì •\n",
    "X_train_encoded = X_train_encoded.drop(columns=[\"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"])  # Featureë§Œ ë‚¨ê¹€\n",
    "\n",
    "# âœ… ì „ì²´ ë°ì´í„°ì—ì„œ 8:2ë¡œ Train-Validation ë¶„í•  (Validationì€ ì›ë³¸ì—ì„œ 20% ìœ ì§€)\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train_encoded, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# âœ… IVF(1) ë°ì´í„°ë§Œ ì„ íƒí•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "ivf_mask = (X_train_split[\"ì‹œìˆ  ìœ í˜•\"] == 1)\n",
    "X_train_ivf = X_train_split[ivf_mask]\n",
    "y_train_ivf = y_train_split[ivf_mask]\n",
    "\n",
    "print(f\"Train ë°ì´í„° ìˆ˜ (IVF=1): {X_train_ivf.shape[0]}\")\n",
    "print(f\"Validation ë°ì´í„° ìˆ˜: {X_val.shape[0]}\")\n",
    "\n",
    "# âœ… RandomForest ëª¨ë¸ í•™ìŠµ (IVF(1) ë°ì´í„°ë¡œë§Œ í•™ìŠµ)\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300, \n",
    "    max_depth=15, \n",
    "    min_samples_split=5,   # í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_ivf, y_train_ivf)\n",
    "\n",
    "\n",
    "# âœ… ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥ í‰ê°€\n",
    "print(\"\\nğŸ”¥ Validation Set Performance ğŸ”¥\")\n",
    "\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# âœ… ì‹œìˆ  ìœ í˜•ì´ DI(0)ì¸ ê²½ìš° ê°•ì œë¡œ 0ìœ¼ë¡œ ì„¤ì •\n",
    "y_val_pred_rf[X_val[\"ì‹œìˆ  ìœ í˜•\"] == 0] = 0\n",
    "\n",
    "# âœ… Confusion Matrix ì¶œë ¥\n",
    "print(\"\\nğŸ”¥ Confusion Matrix ğŸ”¥\")\n",
    "cm_rf = confusion_matrix(y_val, y_val_pred_rf)\n",
    "print(cm_rf)\n",
    "\n",
    "# âœ… Classification Report (ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ ì¶œë ¥)\n",
    "print(\"\\nğŸ”¥ Classification Report ğŸ”¥\")\n",
    "print(classification_report(y_val, y_val_pred_rf, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5d7ca46-bbc3-4eca-8a4f-de85761c16be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ '/Users/yudayeon/Desktop/LGAimers/submission/baseline_submit333.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "rf_preds_test = rf_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "# âœ… DI(0)ì¸ ê²½ìš° ê°•ì œë¡œ 0ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "final_preds_test_binary = (rf_preds_test >= 0.5).astype(int)\n",
    "final_preds_test_binary[X_test_encoded[\"ì‹œìˆ  ìœ í˜•\"] == 0] = 0\n",
    "\n",
    "# âœ… ì œì¶œ íŒŒì¼ ë¡œë“œ\n",
    "submission_path = '/Users/yudayeon/Desktop/LGAimers/submission/sample_submission.csv'\n",
    "sample_submission = pd.read_csv(submission_path)\n",
    "\n",
    "# âœ… ì˜ˆì¸¡ê°’ ì €ì¥\n",
    "sample_submission['probability'] = rf_preds_test\n",
    "\n",
    "# âœ… CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "output_path = '/Users/yudayeon/Desktop/LGAimers/submission/baseline_submit333.csv'\n",
    "sample_submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dec545d2-0542-4ddf-ac79-81ebcba84232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ë°ì´í„° ìˆ˜ (IVF=1): 200045\n",
      "Validation ë°ì´í„° ìˆ˜: 51271\n",
      "\n",
      "ğŸ”¥ Validation Set Performance ğŸ”¥\n",
      "\n",
      "ğŸ”¥ Confusion Matrix ğŸ”¥\n",
      "[[36603  1542]\n",
      " [11563  1563]]\n",
      "\n",
      "ğŸ”¥ Classification Report ğŸ”¥\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7599    0.9596    0.8482     38145\n",
      "           1     0.5034    0.1191    0.1926     13126\n",
      "\n",
      "    accuracy                         0.7444     51271\n",
      "   macro avg     0.6317    0.5393    0.5204     51271\n",
      "weighted avg     0.6943    0.7444    0.6803     51271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# âœ… ê¸°ì¡´ ì¸ì½”ë”©ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "X_train_encoded = pd.read_csv('data/train_encoded.csv')\n",
    "X_test_encoded = pd.read_csv('data/test_encoded.csv')\n",
    "\n",
    "# âœ… Target ë³€ìˆ˜ ë¶„ë¦¬\n",
    "y_train = X_train_encoded[\"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"]  # 'target' ì»¬ëŸ¼ì„ ì •ë‹µ ë ˆì´ë¸”ë¡œ ì„¤ì •\n",
    "X_train_encoded = X_train_encoded.drop(columns=[\"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"])  # Featureë§Œ ë‚¨ê¹€\n",
    "\n",
    "# âœ… ì „ì²´ ë°ì´í„°ì—ì„œ 8:2ë¡œ Train-Validation ë¶„í•  (Validationì€ ì›ë³¸ì—ì„œ 20% ìœ ì§€)\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train_encoded, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# âœ… IVF(1) ë°ì´í„°ë§Œ ì„ íƒí•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "ivf_mask = (X_train_split[\"ì‹œìˆ  ìœ í˜•\"] == 1)\n",
    "X_train_ivf = X_train_split[ivf_mask]\n",
    "y_train_ivf = y_train_split[ivf_mask]\n",
    "\n",
    "print(f\"Train ë°ì´í„° ìˆ˜ (IVF=1): {X_train_ivf.shape[0]}\")\n",
    "print(f\"Validation ë°ì´í„° ìˆ˜: {X_val.shape[0]}\")\n",
    "\n",
    "# âœ… RandomForest ëª¨ë¸ í•™ìŠµ (IVF(1) ë°ì´í„°ë¡œë§Œ í•™ìŠµ)\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,  # íŠ¸ë¦¬ ê°œìˆ˜ ì¦ê°€\n",
    "    max_depth=25,      # íŠ¸ë¦¬ ê¹Šì´ ì¦ê°€\n",
    "    min_samples_split=3,  # ë¶„í•  ê¸°ì¤€ ì™„í™”\n",
    "    min_samples_leaf=2,  # ìµœì†Œ ë¦¬í”„ ë…¸ë“œ í¬ê¸° ê°ì†Œ\n",
    "    max_features='sqrt',  # ìµœì ì˜ ë³€ìˆ˜ ì„ íƒ\n",
    "    bootstrap=True,  # ë¶€íŠ¸ìŠ¤íŠ¸ë˜í•‘ ì‚¬ìš©\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # ë³‘ë ¬ ì²˜ë¦¬ í™œì„±í™”\n",
    ")\n",
    "rf_model.fit(X_train_ivf, y_train_ivf)\n",
    "\n",
    "# âœ… ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥ í‰ê°€\n",
    "print(\"\\nğŸ”¥ Validation Set Performance ğŸ”¥\")\n",
    "\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# âœ… ì‹œìˆ  ìœ í˜•ì´ DI(0)ì¸ ê²½ìš° ê°•ì œë¡œ 0ìœ¼ë¡œ ì„¤ì •\n",
    "y_val_pred_rf[X_val[\"ì‹œìˆ  ìœ í˜•\"] == 0] = 0\n",
    "\n",
    "# âœ… Confusion Matrix ì¶œë ¥\n",
    "print(\"\\nğŸ”¥ Confusion Matrix ğŸ”¥\")\n",
    "cm_rf = confusion_matrix(y_val, y_val_pred_rf)\n",
    "print(cm_rf)\n",
    "\n",
    "# âœ… Classification Report (ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ ì¶œë ¥)\n",
    "print(\"\\nğŸ”¥ Classification Report ğŸ”¥\")\n",
    "print(classification_report(y_val, y_val_pred_rf, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797f022-f504-4f0d-8374-5096d19508bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2dc9f3-0d1e-49c5-8ce6-d25ceed55ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e56640b-08a3-4665-9279-969906b4f945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c203e4e2-2059-4883-83ad-e394610d1b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd9507d-477a-41ad-aff9-14cbf91926c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca904964-ce6a-470d-9c5f-77edf53d63c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c9bf419-b117-4f33-be3c-aee52bd680d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ë°ì´í„° ìˆ˜ (IVF=1): 200045\n",
      "Validation ë°ì´í„° ìˆ˜: 51271\n",
      "\n",
      "ğŸ”¥ Validation Set Performance ğŸ”¥\n",
      "\n",
      "ğŸ”¥ Confusion Matrix ğŸ”¥\n",
      "[[22961 15184]\n",
      " [ 3450  9676]]\n",
      "\n",
      "ğŸ”¥ Classification Report ğŸ”¥\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8694    0.6019    0.7114     38145\n",
      "           1     0.3892    0.7372    0.5095     13126\n",
      "\n",
      "    accuracy                         0.6366     51271\n",
      "   macro avg     0.6293    0.6696    0.6104     51271\n",
      "weighted avg     0.7464    0.6366    0.6597     51271\n",
      "\n",
      "\n",
      "âœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ '/Users/yudayeon/Desktop/LGAimers/submission/baseline_submit3.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "####################################################################ì•„ëª°ë‘\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# âœ… ê¸°ì¡´ ì¸ì½”ë”©ëœ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "X_train_encoded = pd.read_csv('data/train_encoded.csv')\n",
    "X_test_encoded = pd.read_csv('data/test_encoded.csv')\n",
    "\n",
    "# âœ… Target ë³€ìˆ˜ ë¶„ë¦¬\n",
    "y_train = X_train_encoded[\"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"]  # 'target' ì»¬ëŸ¼ì„ ì •ë‹µ ë ˆì´ë¸”ë¡œ ì„¤ì •\n",
    "X_train_encoded = X_train_encoded.drop(columns=[\"ì„ì‹  ì„±ê³µ ì—¬ë¶€\"])  # Featureë§Œ ë‚¨ê¹€\n",
    "\n",
    "# âœ… ì „ì²´ ë°ì´í„°ì—ì„œ 8:2ë¡œ Train-Validation ë¶„í•  (Validationì€ ì›ë³¸ì—ì„œ 20% ìœ ì§€)\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train_encoded, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# âœ… IVF(1) ë°ì´í„°ë§Œ ì„ íƒí•˜ì—¬ í•™ìŠµ ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "ivf_mask = (X_train_split[\"ì‹œìˆ  ìœ í˜•\"] == 1)\n",
    "X_train_ivf = X_train_split[ivf_mask]\n",
    "y_train_ivf = y_train_split[ivf_mask]\n",
    "\n",
    "print(f\"Train ë°ì´í„° ìˆ˜ (IVF=1): {X_train_ivf.shape[0]}\")\n",
    "print(f\"Validation ë°ì´í„° ìˆ˜: {X_val.shape[0]}\")\n",
    "\n",
    "# âœ… RandomForest ëª¨ë¸ í•™ìŠµ (IVF(1) ë°ì´í„°ë¡œë§Œ í•™ìŠµ)\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,  # ë” ë§ì€ íŠ¸ë¦¬ ì‚¬ìš©\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=5,  # ë¦¬í”„ ë…¸ë“œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ì§€ì •í•˜ì—¬ ê³¼ì í•© ë°©ì§€\n",
    "    class_weight='balanced',  # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_ivf, y_train_ivf)\n",
    "\n",
    "# âœ… XGBoost ëª¨ë¸ í•™ìŠµ (ì„ íƒ ì‚¬í•­: ì•™ìƒë¸” ëª¨ë¸ ê°œì„ )\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    scale_pos_weight=len(y_train_ivf[y_train_ivf == 0]) / len(y_train_ivf[y_train_ivf == 1]),\n",
    "    random_state=42\n",
    ")\n",
    "xgb_model.fit(X_train_ivf, y_train_ivf)\n",
    "\n",
    "# âœ… ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì„±ëŠ¥ í‰ê°€\n",
    "print(\"\\nğŸ”¥ Validation Set Performance ğŸ”¥\")\n",
    "\n",
    "rf_preds_val = rf_model.predict_proba(X_val)[:, 1]\n",
    "xgb_preds_val = xgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# âœ… ì„ê³„ê°’ ì¡°ì • (ê¸°ë³¸ 0.5 -> 0.3ìœ¼ë¡œ ì¡°ì •í•˜ì—¬ Recall í–¥ìƒ)\n",
    "threshold = 0.5\n",
    "final_preds_val = (0.5 * rf_preds_val) + (0.5 * xgb_preds_val)\n",
    "y_val_pred_rf = (final_preds_val >= threshold).astype(int)\n",
    "\n",
    "# âœ… ì‹œìˆ  ìœ í˜•ì´ DI(0)ì¸ ê²½ìš° ê°•ì œë¡œ 0ìœ¼ë¡œ ì„¤ì •\n",
    "y_val_pred_rf[X_val[\"ì‹œìˆ  ìœ í˜•\"] == 0] = 0\n",
    "\n",
    "# âœ… Confusion Matrix ì¶œë ¥\n",
    "print(\"\\nğŸ”¥ Confusion Matrix ğŸ”¥\")\n",
    "cm_rf = confusion_matrix(y_val, y_val_pred_rf)\n",
    "print(cm_rf)\n",
    "\n",
    "# âœ… Classification Report (ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ ì¶œë ¥)\n",
    "print(\"\\nğŸ”¥ Classification Report ğŸ”¥\")\n",
    "print(classification_report(y_val, y_val_pred_rf, digits=4))\n",
    "\n",
    "# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "rf_preds_test = rf_model.predict_proba(X_test_encoded)[:, 1]\n",
    "xgb_preds_test = xgb_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "# âœ… ìµœì¢… ì•™ìƒë¸” ì˜ˆì¸¡ (ê°€ì¤‘ í‰ê· )\n",
    "final_preds_test = (0.5 * rf_preds_test) + (0.5 * xgb_preds_test)\n",
    "final_preds_test_binary = (final_preds_test >= threshold).astype(int)\n",
    "final_preds_test_binary[X_test_encoded[\"ì‹œìˆ  ìœ í˜•\"] == 0] = 0\n",
    "\n",
    "# âœ… ì œì¶œ íŒŒì¼ ë¡œë“œ\n",
    "submission_path = '/Users/yudayeon/Desktop/LGAimers/submission/sample_submission.csv'\n",
    "sample_submission = pd.read_csv(submission_path)\n",
    "\n",
    "# âœ… ì˜ˆì¸¡ê°’ ì €ì¥\n",
    "sample_submission['probability'] = final_preds_test\n",
    "\n",
    "# âœ… CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "output_path = '/Users/yudayeon/Desktop/LGAimers/submission/baseline_submit3.csv'\n",
    "sample_submission.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ… ì˜ˆì¸¡ ê²°ê³¼ê°€ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cfc35b6-0e93-491a-a129-5ce96f60dbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹œìˆ  ìœ í˜•\n",
      "1.0    0.975459\n",
      "0.0    0.024541\n",
      "Name: proportion, dtype: float64\n",
      "ì‹œìˆ  ìœ í˜•\n",
      "1.0    0.97584\n",
      "0.0    0.02416\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded[\"ì‹œìˆ  ìœ í˜•\"].value_counts(normalize=True))  # í•™ìŠµ ë°ì´í„° ë¶„í¬\n",
    "print(X_test_encoded[\"ì‹œìˆ  ìœ í˜•\"].value_counts(normalize=True))  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9bfa75-8b27-4654-bff4-2fd11d356d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
